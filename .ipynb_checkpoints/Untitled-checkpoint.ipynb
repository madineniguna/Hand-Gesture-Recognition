{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os,sys\n",
    "\n",
    "# Create the directory structure\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "    os.makedirs(\"data/train\")\n",
    "    os.makedirs(\"data/test\")\n",
    "    os.makedirs(\"data/train/0\")\n",
    "    os.makedirs(\"data/train/1\")\n",
    "    os.makedirs(\"data/train/2\")\n",
    "    os.makedirs(\"data/train/3\")\n",
    "    os.makedirs(\"data/train/4\")\n",
    "    os.makedirs(\"data/train/5\")\n",
    "    os.makedirs(\"data/test/0\")\n",
    "    os.makedirs(\"data/test/1\")\n",
    "    os.makedirs(\"data/test/2\")\n",
    "    os.makedirs(\"data/test/3\")\n",
    "    os.makedirs(\"data/test/4\")\n",
    "    os.makedirs(\"data/test/5\")\n",
    "    \n",
    "\n",
    "# Train or test \n",
    "mode = 'test'\n",
    "directory = 'data/'+mode+'/'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    # Simulating mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Getting count of existing images\n",
    "    count = {'zero': len(os.listdir(directory+\"/0\")),\n",
    "             'one': len(os.listdir(directory+\"/1\")),\n",
    "             'two': len(os.listdir(directory+\"/2\")),\n",
    "             'three': len(os.listdir(directory+\"/3\")),\n",
    "             'four': len(os.listdir(directory+\"/4\")),\n",
    "             'five': len(os.listdir(directory+\"/5\"))}\n",
    "    \n",
    "    # Printing the count in each set to the screen\n",
    "    cv2.putText(frame, \"MODE : \"+mode, (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"IMAGE COUNT\", (10, 100), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"ZERO : \"+str(count['zero']), (10, 120), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"ONE : \"+str(count['one']), (10, 140), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"TWO : \"+str(count['two']), (10, 160), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"THREE : \"+str(count['three']), (10, 180), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"FOUR : \"+str(count['four']), (10, 200), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    cv2.putText(frame, \"FIVE : \"+str(count['five']), (10, 220), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)\n",
    "    \n",
    "    # Coordinates of the ROI\n",
    "    x1 = int(0.5*frame.shape[1])\n",
    "    y1 = 10\n",
    "    x2 = frame.shape[1]-10\n",
    "    y2 = int(0.5*frame.shape[1])\n",
    "    # Drawing the ROI\n",
    "    # The increment/decrement by 1 is to compensate for the bounding box\n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255,0,0) ,1)\n",
    "    # Extracting the ROI\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    roi = cv2.resize(roi, (64, 64)) \n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "   #RGB to gray image\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    #applying thrsholding\n",
    "    _, roi = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    \n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == 27: # esc key\n",
    "        break\n",
    "    if interrupt & 0xFF == ord('0'):\n",
    "        cv2.imwrite(directory+'0/'+str(count['zero'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('1'):\n",
    "        cv2.imwrite(directory+'1/'+str(count['one'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('2'):\n",
    "        cv2.imwrite(directory+'2/'+str(count['two'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('3'):\n",
    "        cv2.imwrite(directory+'3/'+str(count['three'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('4'):\n",
    "        cv2.imwrite(directory+'4/'+str(count['four'])+'.jpg', roi)\n",
    "    if interrupt & 0xFF == ord('5'):\n",
    "        cv2.imwrite(directory+'5/'+str(count['five'])+'.jpg', roi)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55500 images belonging to 37 classes.\n",
      "Found 42001 images belonging to 37 classes.\n",
      "Epoch 1/10\n",
      "200000/200000 [==============================] - 9881s 49ms/step - loss: 0.0217 - acc: 0.9943 - val_loss: 0.0042 - val_acc: 0.9996\n",
      "Epoch 2/10\n",
      "200000/200000 [==============================] - 8897s 44ms/step - loss: 0.0165 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9997\n",
      "Epoch 3/10\n",
      "200000/200000 [==============================] - 9644s 48ms/step - loss: 0.0241 - acc: 0.9981 - val_loss: 0.0713 - val_acc: 0.9952\n",
      "Epoch 4/10\n",
      "200000/200000 [==============================] - 9674s 48ms/step - loss: 0.0331 - acc: 0.9977 - val_loss: 0.0051 - val_acc: 0.9997\n",
      "Epoch 5/10\n",
      "200000/200000 [==============================] - 9837s 49ms/step - loss: 0.0359 - acc: 0.9976 - val_loss: 0.0138 - val_acc: 0.9991\n",
      "Epoch 6/10\n",
      "200000/200000 [==============================] - 9622s 48ms/step - loss: 0.0338 - acc: 0.9978 - val_loss: 0.0077 - val_acc: 0.9995\n",
      "Epoch 7/10\n",
      "200000/200000 [==============================] - 9589s 48ms/step - loss: 0.0352 - acc: 0.9977 - val_loss: 0.0064 - val_acc: 0.9996\n",
      "Epoch 8/10\n",
      "200000/200000 [==============================] - 9226s 46ms/step - loss: 0.0428 - acc: 0.9973 - val_loss: 0.0082 - val_acc: 0.9995\n",
      "Epoch 9/10\n",
      "200000/200000 [==============================] - 9099s 45ms/step - loss: 0.0461 - acc: 0.9971 - val_loss: 0.0086 - val_acc: 0.9994\n",
      "Epoch 10/10\n",
      "200000/200000 [==============================] - 9589s 48ms/step - loss: 0.0486 - acc: 0.9969 - val_loss: 0.0150 - val_acc: 0.9991\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Step 1 - Building the CNN\n",
    "\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=37, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy for more than 2\n",
    "\n",
    "\n",
    "# Step 2 - Preparing the train/test data and training the model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Gesture Image Pre-Processed Data',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=5,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=5,\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='categorical') \n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=200000, # No of images in training set\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=10000)# No of images in test set\n",
    "\n",
    "\n",
    "# Saving the model\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "classifier.save_weights('model-bw.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40501 images belonging to 37 classes.\n",
      "Confusion Matrix\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [25 30 26 ... 29 37  0]\n",
      " [34 26 20 ... 35 29  0]\n",
      " ...\n",
      " [24 20 26 ... 27 31  0]\n",
      " [27 32 24 ... 28 37  0]\n",
      " [34 40 35 ... 26 24  0]]\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=5,\n",
    "                                            classes= [' ','0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R'\n",
    "               ,'S','T','U','V','W','X','Y','Z'],\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='categorical') \n",
    "batch_size = 5\n",
    "target_names = [' ','0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R'\n",
    "               ,'S','T','U','V','W','X','Y','Z']\n",
    "Y_pred = classifier.predict_generator(test_set, 40501 // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_set.classes, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import operator\n",
    "import cv2\n",
    "import sys, os\n",
    "\n",
    "# Loading the model\n",
    "json_file = open(\"model-bw.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model-bw.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Category dictionary\n",
    "categories = {0: ' ', 1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9', 11: 'A'\n",
    "             ,12: 'B', 13: 'C', 14: 'D', 15: 'E', 16: 'F', 17: 'G', 18: 'H', 19: 'I', 20: 'J', 21: 'K', 22: 'L', 23: 'M',\n",
    "             24: 'N', 25: 'O', 26: 'P', 27: 'Q', 28: 'R', 29: 'S', 30: 'T', 31: 'U', 32: 'V', 33: 'W', 34: 'X', 35: 'Y', 36: 'Z'}\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    # Simulating mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Got this from collect-data.py\n",
    "    # Coordinates of the ROI\n",
    "    x1 = int(0.5*frame.shape[1])\n",
    "    y1 = 10\n",
    "    x2 = frame.shape[1]-10\n",
    "    y2 = int(0.5*frame.shape[1])\n",
    "    # Drawing the ROI\n",
    "    # The increment/decrement by 1 is to compensate for the bounding box\n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255,0,0) ,1)\n",
    "    # Extracting the ROI\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    \n",
    "  \n",
    "    roi = cv2.resize(roi, (64, 64)) \n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, test_image = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"test\", test_image)\n",
    "    # Batch of 1\n",
    "    result = loaded_model.predict(test_image.reshape(1, 64, 64, 1))\n",
    "    prediction = {                 ' ': result[0][0], \n",
    "                  'Lights on': result[0][1], \n",
    "                  'Lights off': result[0][2],\n",
    "                  'Fan on ': result[0][3],\n",
    "                  'Fan off': result[0][4],\n",
    "                  'Charging on': result[0][5], \n",
    "                  'Fan off': result[0][6], \n",
    "                  'Lights off': result[0][7], \n",
    "                  'Charging on': result[0][8],\n",
    "                  'Charging on': result[0][9],\n",
    "                  'Charging on': result[0][10],\n",
    "                  'Charging on': result[0][11],\n",
    "                  'Charging off': result[0][12], \n",
    "                  'Charging on': result[0][13], \n",
    "                  'Lights on': result[0][14],\n",
    "                  'Lights off': result[0][15],\n",
    "                  'Lights on': result[0][16],\n",
    "                  'Lights off': result[0][17],\n",
    "                  'lights on': result[0][18], \n",
    "                  'Fan on': result[0][19], \n",
    "                  'Fan off': result[0][20],\n",
    "                  'Fan on': result[0][21],\n",
    "                  'Fan on': result[0][22],\n",
    "                  'Fan on': result[0][23],\n",
    "                  'Fan off': result[0][24], \n",
    "                  'Fan off': result[0][25], \n",
    "                  'Fan off': result[0][26],\n",
    "                  'Fan on': result[0][27],\n",
    "                  'Lights off': result[0][28],\n",
    "                  'Lights off': result[0][29],\n",
    "                  'Lights on': result[0][30], \n",
    "                  'Lights off': result[0][31], \n",
    "                  'Lights on': result[0][32],\n",
    "                  'lights off': result[0][33],\n",
    "                  'Charging off': result[0][34],\n",
    "                  'Charging off': result[0][35],\n",
    "                  'Charging on': result[0][36],\n",
    "                 }\n",
    "    # Sorting based on top prediction\n",
    "    prediction = sorted(prediction.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    # Displaying the predictions\n",
    "    cv2.putText(frame, prediction[0][0], (10, 120), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,255), 1)    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == 27: # esc key\n",
    "        break\n",
    "         \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
